# llm_4_531

## 5/3/1 루틴을 생성해주는 LLM
- 5/3/1 루틴을 생성해주는 LLM
- 5/3/1 루틴을 직접 계산하기는 번거롭다.
- 내 RM(최대 중량)만 알려주면 5/3/1 루틴을 알아서 생성해주는 LLM을 개발하게 됐습니다.

### Base Model
[kanana](https://huggingface.co/kakaocorp/kanana-nano-2.1b-base)
- 한국어 입출력이 가능해야해서 이 모델을 선택
- 또한 모델 크기도 3B이하로 사용해야 하는 상황
- 이 조건에서 성능이 제일 우수하다고 판단해 이를 사용

### 튜닝 방법
#### 데이터 준비
- 한국어로 5/3/1 루틴을 만들어달라는 요청이 왔을 때 이를 수행해야함.
    - 이를 위해 random함수를 이용해 데이터를 생성
    - 질문과 대답 쌍으로 준비
    - instruction은 어떤 작업에 대한 데이터인지 설명
        - ex "사용자가 입력한 복수의 1RM을 이용해 기본적인 5/3/1 루틴을 각 1RM 당 하나씩 생성하세요."
    - 질문과 대답은 여러개를 만든 후 그 중에서 랜덤으로 하나만 선택해 생성하게 함
        - 훈련 시 입력과 출력을 다양하게 함으로써 실제 사용 시 무리없게 사용하기 위함
    - 그 후 json으로 저장
- 세트, 중량 계산 방식은 직접 학습시키지 않고 계산된 중량을 바탕으로 5/3/1 루틴을 만든 후 이를 학습
- 중량의 경우 RM을 random.randrange로 랜덤으로 만들 때 5 단위로 만들게 함
    - 보통 기구가 2.5나 5단위기 때문. 2.5로 안한 이유는 random.randrange가 정수만 지원하기 때문
- 실제 루틴 중량을 계산할 땐 2.5 단위로 나오게 조정
- 기본적으로 사용한 모델이 작아서 설명 혹은 수식만 학습시키면 결과가 제대로 안나오기 때문에 이 방식을 사용.

#### 튜닝
- LoRA 튜닝을 사용
    - full-finetuning의 경우 양질의 데이터 확보가 불가능한 상황
    - 또한 개발 환경도 full-finetuning에 맞지 않다
    - 양자화의 경우 base model을 작은 것을 선택했기 때문에 굳이 할 필요가 없다고 생각함
    - 이 모두를 종합했을 때 가장 나은 선택지는 LoRA튜닝이라 판단

#### 테스트
- 테스트의 경우 직접 프롬프트를 입력하면서 수행
- 생성한 5/3/1 루틴이 내가 입력한 RM에 맞는지 여부를 확인

### 개발 환경
- 기본적으로 로컬 환경에서 개발
- RTX 3070
- CUDA 12.6
- OS : ubuntu22.04LTS(Linux)
- 그 외 정보는 requirements.txt를 확인해 주시기 바랍니다.

### 튜닝한 모델
[llm_4_531](https://huggingface.co/jayiuk/llm_4_531/tree/main)

### 사용법
- distribution 디렉토리로 이동
- streamlit run app.py 명령어 사용
- 그 후 사용하면 됩니다.
    - 답변 생성 시간이 좀 걸립니다.
