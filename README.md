# llm_4_531

## 5/3/1 루틴을 생성해주는 LLM

### Base Model
[kanana](https://huggingface.co/kakaocorp/kanana-nano-2.1b-base)
- 한국어 입출력이 가능해야해서 이 모델을 선택
- 또한 모델 크기도 3B이하로 사용해야 하는 상황
- 이 조건에서 성능이 제일 우수하다고 판단해 이를 사용

### 튜닝 방법
#### 데이터 준비
- 한국어로 5/3/1 루틴을 만들어달라는 요청이 왔을 때 이를 수행해야함.
    - 이를 위해 random함수를 이용해 데이터를 생성
    - 질문과 대답 쌍으로 준비
    - 질문과 대답은 여러개를 만든 후 그 중에서 랜덤으로 하나만 선택해 생성하게 함
        - 훈련 시 입력과 출력을 다양하게 함으로써 실제 사용 시 무리없게 사용하기 위함
    - 그 후 json으로 저장

#### 튜닝
- LoRA 튜닝을 사용
    - full-finetuning의 경우 양질의 데이터 확보가 불가능한 상황
    - 또한 개발 환경도 full-finetuning에 맞지 않다
    - 양자화의 경우 base model을 작은 것을 선택했기 때문에 굳이 할 필요가 없다고 생각함
    - 이 모두를 종합했을 때 가장 나은 선택지는 LoRA튜닝이라 판단

