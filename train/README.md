# 실제 튜닝

## 실제 튜닝 및 허깅페이스에 업로드를 할 때 쓴 코드들

### 파일별 설명

- dataset.py
    - 데이터를 데이터셋으로 만드는 모듈
    - 데이터의 output부분은 여러 문자열을 가진 리스트 형식
    - 이를 하나의 문자열을 가진 리스트로 바꿔줌
    - 원래 있던 문자열 구분은 줄바꿈으로 함

- tuning.py
    - 실제 튜닝을 하는 모듈
    - EOS 토큰을 PAD 토큰으로 설정
        - 문장 길이가 다 다름 -> PAD토큰을 써서 이를 맞춘다. -> 여기선 이를 EOS토큰을 썼다.
        - 좋은 방법은 아니지만 pad token이 없어서 일단 이렇게 진행.
    - 랭크는 8로 설정
        - 4로 하면 성능이 낮아질 수 있어서 일단 8로 설정
        - 성능이 안좋으면 64까지 올리려고는 했지만 일단 8로 해도 어느정도는 괜찮아 보여서 이렇게 진행
    - lora_alpha
        - 쉽게 말해 lora에서 학습된 행렬을 원래 고정된 가중치에 얼마나 반영할 지 결정하는 요소
        - 이 역시 너무 크면 오버피팅 위험이 있어 16으로 진행
    - 에포크마다 checkpoint 저장
        - 아무래도 로컬 환경에서 돌리다보니 gpu 성능이 크게 좋지는 않다
        - loss가 0.05 밑으로 떨어지면 학습 중단 후 테스트를 하는 방식으로 진행
        - 그러기 위해 각 에포크마다 체크포인트 저장

- upload.py
    - 허깅페이스에 모델 업로드
    - 사용 편의를 위해 로라 어댑터와 베이스모델을 합쳐서 저장